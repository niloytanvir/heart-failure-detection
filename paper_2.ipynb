{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "paper-2-feature final.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQajA56LMYLq"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGPmwsIUMYJY"
      },
      "source": [
        "url='https://raw.githubusercontent.com/niloytanvir/heart-failure-data/main/Data/heart_failure_clinical_records_dataset.csv'\n",
        "data = pd.read_csv(url)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_U0kxVazMYGy"
      },
      "source": [
        "x = data.iloc[:,:-1]\n",
        "y = data.iloc[:,12]"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "MM2SzxQJWhsn",
        "outputId": "52ae1a91-5d72-487c-cbf1-c8c617d60461"
      },
      "source": [
        "x.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>anaemia</th>\n",
              "      <th>creatinine_phosphokinase</th>\n",
              "      <th>diabetes</th>\n",
              "      <th>ejection_fraction</th>\n",
              "      <th>high_blood_pressure</th>\n",
              "      <th>platelets</th>\n",
              "      <th>serum_creatinine</th>\n",
              "      <th>serum_sodium</th>\n",
              "      <th>sex</th>\n",
              "      <th>smoking</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>75.0</td>\n",
              "      <td>0</td>\n",
              "      <td>582</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "      <td>265000.00</td>\n",
              "      <td>1.9</td>\n",
              "      <td>130</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>55.0</td>\n",
              "      <td>0</td>\n",
              "      <td>7861</td>\n",
              "      <td>0</td>\n",
              "      <td>38</td>\n",
              "      <td>0</td>\n",
              "      <td>263358.03</td>\n",
              "      <td>1.1</td>\n",
              "      <td>136</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>65.0</td>\n",
              "      <td>0</td>\n",
              "      <td>146</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>162000.00</td>\n",
              "      <td>1.3</td>\n",
              "      <td>129</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>50.0</td>\n",
              "      <td>1</td>\n",
              "      <td>111</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>210000.00</td>\n",
              "      <td>1.9</td>\n",
              "      <td>137</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>65.0</td>\n",
              "      <td>1</td>\n",
              "      <td>160</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>327000.00</td>\n",
              "      <td>2.7</td>\n",
              "      <td>116</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    age  anaemia  creatinine_phosphokinase  ...  sex  smoking  time\n",
              "0  75.0        0                       582  ...    1        0     4\n",
              "1  55.0        0                      7861  ...    1        0     6\n",
              "2  65.0        0                       146  ...    1        1     7\n",
              "3  50.0        1                       111  ...    1        0     7\n",
              "4  65.0        1                       160  ...    0        0     8\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-DX69JsX4e3",
        "outputId": "e8e53641-e218-45d8-8298-6722af08518e"
      },
      "source": [
        "y.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    1\n",
              "1    1\n",
              "2    1\n",
              "3    1\n",
              "4    1\n",
              "Name: DEATH_EVENT, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B44-jRxrMYA3"
      },
      "source": [
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import f_classif"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kontj-XXMX9p"
      },
      "source": [
        "FIT_FEATURES = SelectKBest(score_func = f_classif)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xJHsUI6kP1tB",
        "outputId": "b9a337ef-9137-4578-bc82-f063efe50700"
      },
      "source": [
        "FIT_FEATURES.fit(x,y)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SelectKBest(k=10, score_func=<function f_classif at 0x7f7581a65dd0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xH61XX6AMXwR"
      },
      "source": [
        "Score_Col = pd.DataFrame(FIT_FEATURES.scores_ , columns=['score_val'])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "id": "OCXW7fYBVjcv",
        "outputId": "e0a7ad54-a684-48c7-d3a0-a7e791d243e1"
      },
      "source": [
        "Score_Col"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>score_val</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>20.435946</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.310096</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.173259</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.001121</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>23.094063</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1.881937</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.718880</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>28.158492</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>11.765331</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.005534</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.047333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>114.181264</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     score_val\n",
              "0    20.435946\n",
              "1     1.310096\n",
              "2     1.173259\n",
              "3     0.001121\n",
              "4    23.094063\n",
              "5     1.881937\n",
              "6     0.718880\n",
              "7    28.158492\n",
              "8    11.765331\n",
              "9     0.005534\n",
              "10    0.047333\n",
              "11  114.181264"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5-3Gu6RQnIW"
      },
      "source": [
        "Name_Col = pd.DataFrame(x.columns)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_MDT1YV1QnaI"
      },
      "source": [
        "top_features = pd.concat([Name_Col,Score_Col], axis=1)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "id": "3ddWYu45Qn46",
        "outputId": "35e1fab5-de72-4f02-b889-d8d469aad1bd"
      },
      "source": [
        "top_features"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>score_val</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>age</td>\n",
              "      <td>20.435946</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>anaemia</td>\n",
              "      <td>1.310096</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>creatinine_phosphokinase</td>\n",
              "      <td>1.173259</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>diabetes</td>\n",
              "      <td>0.001121</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ejection_fraction</td>\n",
              "      <td>23.094063</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>high_blood_pressure</td>\n",
              "      <td>1.881937</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>platelets</td>\n",
              "      <td>0.718880</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>serum_creatinine</td>\n",
              "      <td>28.158492</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>serum_sodium</td>\n",
              "      <td>11.765331</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>sex</td>\n",
              "      <td>0.005534</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>smoking</td>\n",
              "      <td>0.047333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>time</td>\n",
              "      <td>114.181264</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                           0   score_val\n",
              "0                        age   20.435946\n",
              "1                    anaemia    1.310096\n",
              "2   creatinine_phosphokinase    1.173259\n",
              "3                   diabetes    0.001121\n",
              "4          ejection_fraction   23.094063\n",
              "5        high_blood_pressure    1.881937\n",
              "6                  platelets    0.718880\n",
              "7           serum_creatinine   28.158492\n",
              "8               serum_sodium   11.765331\n",
              "9                        sex    0.005534\n",
              "10                   smoking    0.047333\n",
              "11                      time  114.181264"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "uxSYukYIQoBQ",
        "outputId": "11f66d72-fd24-4c5f-e7dd-1493d07914b7"
      },
      "source": [
        "top_features.nlargest(8,'score_val')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>score_val</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>time</td>\n",
              "      <td>114.181264</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>serum_creatinine</td>\n",
              "      <td>28.158492</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ejection_fraction</td>\n",
              "      <td>23.094063</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>age</td>\n",
              "      <td>20.435946</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>serum_sodium</td>\n",
              "      <td>11.765331</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>high_blood_pressure</td>\n",
              "      <td>1.881937</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>anaemia</td>\n",
              "      <td>1.310096</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>creatinine_phosphokinase</td>\n",
              "      <td>1.173259</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                           0   score_val\n",
              "11                      time  114.181264\n",
              "7           serum_creatinine   28.158492\n",
              "4          ejection_fraction   23.094063\n",
              "0                        age   20.435946\n",
              "8               serum_sodium   11.765331\n",
              "5        high_blood_pressure    1.881937\n",
              "1                    anaemia    1.310096\n",
              "2   creatinine_phosphokinase    1.173259"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEPZ1MwwRRHp"
      },
      "source": [
        "Col_to_Drop = ['smoking', 'sex', 'platelets', 'diabetes']"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5PCK7a9RRKq"
      },
      "source": [
        "x = x.drop(Col_to_Drop, axis= 1)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "c4E4zo87RROr",
        "outputId": "6a942dc6-5b1c-49f6-a6e1-6dfea14642a4"
      },
      "source": [
        "x.head()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>anaemia</th>\n",
              "      <th>creatinine_phosphokinase</th>\n",
              "      <th>ejection_fraction</th>\n",
              "      <th>high_blood_pressure</th>\n",
              "      <th>serum_creatinine</th>\n",
              "      <th>serum_sodium</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>75.0</td>\n",
              "      <td>0</td>\n",
              "      <td>582</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "      <td>1.9</td>\n",
              "      <td>130</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>55.0</td>\n",
              "      <td>0</td>\n",
              "      <td>7861</td>\n",
              "      <td>38</td>\n",
              "      <td>0</td>\n",
              "      <td>1.1</td>\n",
              "      <td>136</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>65.0</td>\n",
              "      <td>0</td>\n",
              "      <td>146</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>1.3</td>\n",
              "      <td>129</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>50.0</td>\n",
              "      <td>1</td>\n",
              "      <td>111</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>1.9</td>\n",
              "      <td>137</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>65.0</td>\n",
              "      <td>1</td>\n",
              "      <td>160</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>2.7</td>\n",
              "      <td>116</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    age  anaemia  ...  serum_sodium  time\n",
              "0  75.0        0  ...           130     4\n",
              "1  55.0        0  ...           136     6\n",
              "2  65.0        0  ...           129     7\n",
              "3  50.0        1  ...           137     7\n",
              "4  65.0        1  ...           116     8\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HqAinOu8QoE4"
      },
      "source": [
        "xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size=0.20, random_state=101)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYsBAR0NkNdC"
      },
      "source": [
        "\n",
        "batchSize = [10, 20, 40, 60, 80, 100]\n",
        "epochs = [10, 30, 50,100,200,300]\n",
        "optimizer = ['SGD','Adadelta', 'RMSprop', 'Adagrad','Adam']\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L90LQ079kNhg",
        "outputId": "947a9cca-969e-4311-b4e4-151d52ddf1c1"
      },
      "source": [
        "# Create the param grid\n",
        "param_grid = { 'batch_size' : batchSize,\n",
        "               'epochs' : epochs,\n",
        "               'optimizer' : optimizer}\n",
        "print(param_grid)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'batch_size': [10, 20, 40, 60, 80, 100], 'epochs': [10, 30, 50, 100, 200, 300], 'optimizer': ['SGD', 'Adadelta', 'RMSprop', 'Adagrad', 'Adam']}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTtwb2e4kNlx"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasClassifier"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCGvJz_r5IR_"
      },
      "source": [
        "# F1 Score custom metrics\n",
        "from keras import backend as K\n",
        "def f1_score(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7X6qAp9kNpH"
      },
      "source": [
        "# Function to create model,for KerasClassifier\n",
        "def create_model(optimizer='adam'):\n",
        "    #defining my model\n",
        "    mymodel = Sequential()\n",
        "    mymodel.add(Dense(4, input_dim=8, activation='relu'))\n",
        "    mymodel.add(Dense(1, activation='sigmoid'))\n",
        "    \n",
        "    # Compile the model\n",
        "    mymodel.compile(loss='binary_crossentropy', optimizer=optimizer, metrics = ['accuracy',f1_score,tf.keras.metrics.Precision(),tf.keras.metrics.Recall()])\n",
        "    return mymodel\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3pmPbfWr_l3"
      },
      "source": [
        "# create model\n",
        "model = KerasClassifier(build_fn=create_model)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ko2I28ftkNt4"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "Grid = GridSearchCV(estimator = model, param_grid = param_grid, cv = 3, verbose=2, n_jobs = -1)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3q6nmj2nWIv",
        "outputId": "4bc418a5-74b2-4d2e-829c-f7f618d0f554"
      },
      "source": [
        "Grid_result = Grid.fit(xtrain, ytrain)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 180 candidates, totalling 540 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:  1.6min\n",
            "[Parallel(n_jobs=-1)]: Done 158 tasks      | elapsed:  7.8min\n",
            "[Parallel(n_jobs=-1)]: Done 361 tasks      | elapsed: 15.5min\n",
            "[Parallel(n_jobs=-1)]: Done 540 out of 540 | elapsed: 21.1min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "12/12 [==============================] - 13s 2ms/step - loss: 63.0152 - accuracy: 0.5392 - f1_score: 0.4064 - precision: 0.3216 - recall: 0.4443\n",
            "Epoch 2/300\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 46.4732 - accuracy: 0.5462 - f1_score: 0.4001 - precision: 0.4042 - recall: 0.5592\n",
            "Epoch 3/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 40.4271 - accuracy: 0.5795 - f1_score: 0.4282 - precision: 0.4005 - recall: 0.5521\n",
            "Epoch 4/300\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 32.9829 - accuracy: 0.5769 - f1_score: 0.4374 - precision: 0.3989 - recall: 0.5208\n",
            "Epoch 5/300\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 22.1304 - accuracy: 0.6346 - f1_score: 0.4377 - precision: 0.4023 - recall: 0.4996\n",
            "Epoch 6/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 21.7807 - accuracy: 0.6083 - f1_score: 0.3591 - precision: 0.4081 - recall: 0.4740\n",
            "Epoch 7/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 24.0566 - accuracy: 0.6739 - f1_score: 0.4167 - precision: 0.4153 - recall: 0.4599\n",
            "Epoch 8/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 21.4454 - accuracy: 0.6419 - f1_score: 0.4312 - precision: 0.4210 - recall: 0.4437\n",
            "Epoch 9/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 16.6131 - accuracy: 0.6576 - f1_score: 0.3791 - precision: 0.4253 - recall: 0.4264\n",
            "Epoch 10/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 22.9533 - accuracy: 0.6568 - f1_score: 0.3247 - precision: 0.4317 - recall: 0.4137\n",
            "Epoch 11/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 14.6236 - accuracy: 0.6554 - f1_score: 0.2806 - precision: 0.4354 - recall: 0.3948\n",
            "Epoch 12/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 17.7449 - accuracy: 0.6481 - f1_score: 0.2848 - precision: 0.4383 - recall: 0.3767\n",
            "Epoch 13/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 13.9011 - accuracy: 0.6595 - f1_score: 0.1939 - precision: 0.4400 - recall: 0.3620\n",
            "Epoch 14/300\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 10.0347 - accuracy: 0.6954 - f1_score: 0.3468 - precision: 0.4443 - recall: 0.3503\n",
            "Epoch 15/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 10.9123 - accuracy: 0.6539 - f1_score: 0.2551 - precision: 0.4452 - recall: 0.3367\n",
            "Epoch 16/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 11.4346 - accuracy: 0.6896 - f1_score: 0.3061 - precision: 0.4468 - recall: 0.3258\n",
            "Epoch 17/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 8.2727 - accuracy: 0.6930 - f1_score: 0.2587 - precision: 0.4503 - recall: 0.3163\n",
            "Epoch 18/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 9.7725 - accuracy: 0.6613 - f1_score: 0.2962 - precision: 0.4551 - recall: 0.3107\n",
            "Epoch 19/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 7.8514 - accuracy: 0.6946 - f1_score: 0.4054 - precision: 0.4643 - recall: 0.3092\n",
            "Epoch 20/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 6.7227 - accuracy: 0.7207 - f1_score: 0.3777 - precision: 0.4681 - recall: 0.3049\n",
            "Epoch 21/300\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 6.0600 - accuracy: 0.7094 - f1_score: 0.4272 - precision: 0.4761 - recall: 0.3029\n",
            "Epoch 22/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 6.4067 - accuracy: 0.6858 - f1_score: 0.3746 - precision: 0.4812 - recall: 0.3030\n",
            "Epoch 23/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 6.2163 - accuracy: 0.7136 - f1_score: 0.4465 - precision: 0.4900 - recall: 0.3078\n",
            "Epoch 24/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 4.8653 - accuracy: 0.6992 - f1_score: 0.3680 - precision: 0.4970 - recall: 0.3106\n",
            "Epoch 25/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 3.1622 - accuracy: 0.7312 - f1_score: 0.5426 - precision: 0.5052 - recall: 0.3183\n",
            "Epoch 26/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 3.5498 - accuracy: 0.7317 - f1_score: 0.4529 - precision: 0.5112 - recall: 0.3223\n",
            "Epoch 27/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2.3765 - accuracy: 0.7574 - f1_score: 0.5662 - precision: 0.5184 - recall: 0.3307\n",
            "Epoch 28/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2.5643 - accuracy: 0.7081 - f1_score: 0.5610 - precision: 0.5251 - recall: 0.3373\n",
            "Epoch 29/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2.4681 - accuracy: 0.7440 - f1_score: 0.5413 - precision: 0.5296 - recall: 0.3458\n",
            "Epoch 30/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.8009 - accuracy: 0.7835 - f1_score: 0.6215 - precision: 0.5334 - recall: 0.3552\n",
            "Epoch 31/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.8094 - accuracy: 0.7626 - f1_score: 0.6417 - precision: 0.5388 - recall: 0.3634\n",
            "Epoch 32/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.5334 - accuracy: 0.7352 - f1_score: 0.6176 - precision: 0.5407 - recall: 0.3729\n",
            "Epoch 33/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.8678 - accuracy: 0.7069 - f1_score: 0.6229 - precision: 0.5439 - recall: 0.3821\n",
            "Epoch 34/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.8788 - accuracy: 0.6911 - f1_score: 0.5827 - precision: 0.5448 - recall: 0.3908\n",
            "Epoch 35/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.3306 - accuracy: 0.6880 - f1_score: 0.5679 - precision: 0.5443 - recall: 0.3978\n",
            "Epoch 36/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.3745 - accuracy: 0.6643 - f1_score: 0.5535 - precision: 0.5438 - recall: 0.4069\n",
            "Epoch 37/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.5453 - accuracy: 0.6797 - f1_score: 0.5847 - precision: 0.5450 - recall: 0.4153\n",
            "Epoch 38/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.2758 - accuracy: 0.6676 - f1_score: 0.5503 - precision: 0.5435 - recall: 0.4234\n",
            "Epoch 39/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.3572 - accuracy: 0.6363 - f1_score: 0.5039 - precision: 0.5431 - recall: 0.4295\n",
            "Epoch 40/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.5679 - accuracy: 0.6717 - f1_score: 0.5978 - precision: 0.5408 - recall: 0.4338\n",
            "Epoch 41/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.2272 - accuracy: 0.6955 - f1_score: 0.5836 - precision: 0.5395 - recall: 0.4421\n",
            "Epoch 42/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.2452 - accuracy: 0.6820 - f1_score: 0.6191 - precision: 0.5384 - recall: 0.4467\n",
            "Epoch 43/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.5130 - accuracy: 0.6391 - f1_score: 0.5318 - precision: 0.5364 - recall: 0.4531\n",
            "Epoch 44/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.2912 - accuracy: 0.6365 - f1_score: 0.4981 - precision: 0.5349 - recall: 0.4565\n",
            "Epoch 45/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.1497 - accuracy: 0.6445 - f1_score: 0.5525 - precision: 0.5345 - recall: 0.4620\n",
            "Epoch 46/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.2592 - accuracy: 0.6846 - f1_score: 0.5854 - precision: 0.5336 - recall: 0.4662\n",
            "Epoch 47/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.2293 - accuracy: 0.6332 - f1_score: 0.4328 - precision: 0.5319 - recall: 0.4699\n",
            "Epoch 48/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.0463 - accuracy: 0.6555 - f1_score: 0.5751 - precision: 0.5303 - recall: 0.4740\n",
            "Epoch 49/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.2335 - accuracy: 0.6071 - f1_score: 0.5397 - precision: 0.5285 - recall: 0.4785\n",
            "Epoch 50/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.3841 - accuracy: 0.6139 - f1_score: 0.5149 - precision: 0.5287 - recall: 0.4813\n",
            "Epoch 51/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.9954 - accuracy: 0.6268 - f1_score: 0.4664 - precision: 0.5266 - recall: 0.4840\n",
            "Epoch 52/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.9821 - accuracy: 0.6624 - f1_score: 0.5527 - precision: 0.5257 - recall: 0.4865\n",
            "Epoch 53/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.1601 - accuracy: 0.6031 - f1_score: 0.4491 - precision: 0.5245 - recall: 0.4880\n",
            "Epoch 54/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.0400 - accuracy: 0.6704 - f1_score: 0.5582 - precision: 0.5237 - recall: 0.4908\n",
            "Epoch 55/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.1527 - accuracy: 0.6566 - f1_score: 0.5806 - precision: 0.5230 - recall: 0.4926\n",
            "Epoch 56/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.8941 - accuracy: 0.6668 - f1_score: 0.5099 - precision: 0.5223 - recall: 0.4964\n",
            "Epoch 57/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.9546 - accuracy: 0.6750 - f1_score: 0.5375 - precision: 0.5218 - recall: 0.4980\n",
            "Epoch 58/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.0803 - accuracy: 0.6729 - f1_score: 0.5183 - precision: 0.5218 - recall: 0.5010\n",
            "Epoch 59/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0221 - accuracy: 0.6569 - f1_score: 0.5607 - precision: 0.5212 - recall: 0.5017\n",
            "Epoch 60/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.1291 - accuracy: 0.6676 - f1_score: 0.5261 - precision: 0.5204 - recall: 0.5055\n",
            "Epoch 61/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.9523 - accuracy: 0.6989 - f1_score: 0.5992 - precision: 0.5207 - recall: 0.5079\n",
            "Epoch 62/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.0188 - accuracy: 0.6857 - f1_score: 0.5665 - precision: 0.5205 - recall: 0.5115\n",
            "Epoch 63/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9776 - accuracy: 0.6563 - f1_score: 0.5804 - precision: 0.5207 - recall: 0.5126\n",
            "Epoch 64/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.4143 - accuracy: 0.6237 - f1_score: 0.5484 - precision: 0.5203 - recall: 0.5160\n",
            "Epoch 65/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.8168 - accuracy: 0.7274 - f1_score: 0.5924 - precision: 0.5204 - recall: 0.5168\n",
            "Epoch 66/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.7947 - accuracy: 0.7427 - f1_score: 0.6259 - precision: 0.5210 - recall: 0.5194\n",
            "Epoch 67/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.8296 - accuracy: 0.7312 - f1_score: 0.5922 - precision: 0.5213 - recall: 0.5222\n",
            "Epoch 68/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.8613 - accuracy: 0.7268 - f1_score: 0.6372 - precision: 0.5221 - recall: 0.5253\n",
            "Epoch 69/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.8819 - accuracy: 0.6997 - f1_score: 0.6408 - precision: 0.5224 - recall: 0.5273\n",
            "Epoch 70/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7603 - accuracy: 0.6808 - f1_score: 0.5559 - precision: 0.5217 - recall: 0.5295\n",
            "Epoch 71/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.9302 - accuracy: 0.6765 - f1_score: 0.5596 - precision: 0.5218 - recall: 0.5313\n",
            "Epoch 72/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.7141 - accuracy: 0.7090 - f1_score: 0.5634 - precision: 0.5222 - recall: 0.5333\n",
            "Epoch 73/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.8820 - accuracy: 0.6827 - f1_score: 0.4940 - precision: 0.5219 - recall: 0.5354\n",
            "Epoch 74/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.9195 - accuracy: 0.6378 - f1_score: 0.5734 - precision: 0.5225 - recall: 0.5379\n",
            "Epoch 75/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.8348 - accuracy: 0.7357 - f1_score: 0.6268 - precision: 0.5228 - recall: 0.5399\n",
            "Epoch 76/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.0103 - accuracy: 0.6655 - f1_score: 0.5841 - precision: 0.5224 - recall: 0.5418\n",
            "Epoch 77/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.0408 - accuracy: 0.6919 - f1_score: 0.5301 - precision: 0.5225 - recall: 0.5432\n",
            "Epoch 78/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.9389 - accuracy: 0.6686 - f1_score: 0.5580 - precision: 0.5223 - recall: 0.5451\n",
            "Epoch 79/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.7457 - accuracy: 0.7561 - f1_score: 0.6540 - precision: 0.5233 - recall: 0.5472\n",
            "Epoch 80/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.0438 - accuracy: 0.7017 - f1_score: 0.6380 - precision: 0.5234 - recall: 0.5489\n",
            "Epoch 81/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.8702 - accuracy: 0.7040 - f1_score: 0.6002 - precision: 0.5234 - recall: 0.5508\n",
            "Epoch 82/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.8461 - accuracy: 0.6871 - f1_score: 0.6174 - precision: 0.5237 - recall: 0.5525\n",
            "Epoch 83/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.9633 - accuracy: 0.7299 - f1_score: 0.5233 - precision: 0.5241 - recall: 0.5539\n",
            "Epoch 84/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.4578 - accuracy: 0.6697 - f1_score: 0.5909 - precision: 0.5242 - recall: 0.5563\n",
            "Epoch 85/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.7943 - accuracy: 0.7096 - f1_score: 0.6176 - precision: 0.5251 - recall: 0.5579\n",
            "Epoch 86/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.7920 - accuracy: 0.7210 - f1_score: 0.6237 - precision: 0.5250 - recall: 0.5594\n",
            "Epoch 87/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.7599 - accuracy: 0.7047 - f1_score: 0.6173 - precision: 0.5250 - recall: 0.5605\n",
            "Epoch 88/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.8173 - accuracy: 0.6827 - f1_score: 0.5857 - precision: 0.5251 - recall: 0.5619\n",
            "Epoch 89/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.7912 - accuracy: 0.6827 - f1_score: 0.5786 - precision: 0.5250 - recall: 0.5632\n",
            "Epoch 90/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.7678 - accuracy: 0.7296 - f1_score: 0.5939 - precision: 0.5252 - recall: 0.5645\n",
            "Epoch 91/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.9482 - accuracy: 0.6431 - f1_score: 0.5908 - precision: 0.5256 - recall: 0.5658\n",
            "Epoch 92/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.6711 - accuracy: 0.7225 - f1_score: 0.5727 - precision: 0.5255 - recall: 0.5672\n",
            "Epoch 93/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.7687 - accuracy: 0.6927 - f1_score: 0.5747 - precision: 0.5258 - recall: 0.5682\n",
            "Epoch 94/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.7172 - accuracy: 0.7192 - f1_score: 0.6430 - precision: 0.5263 - recall: 0.5695\n",
            "Epoch 95/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.8772 - accuracy: 0.6956 - f1_score: 0.5985 - precision: 0.5265 - recall: 0.5705\n",
            "Epoch 96/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.7757 - accuracy: 0.6969 - f1_score: 0.6079 - precision: 0.5266 - recall: 0.5722\n",
            "Epoch 97/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.7927 - accuracy: 0.7042 - f1_score: 0.6523 - precision: 0.5267 - recall: 0.5733\n",
            "Epoch 98/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.9158 - accuracy: 0.7290 - f1_score: 0.5444 - precision: 0.5269 - recall: 0.5749\n",
            "Epoch 99/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.0292 - accuracy: 0.6682 - f1_score: 0.5990 - precision: 0.5275 - recall: 0.5754\n",
            "Epoch 100/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.8774 - accuracy: 0.7249 - f1_score: 0.6218 - precision: 0.5276 - recall: 0.5773\n",
            "Epoch 101/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.9943 - accuracy: 0.6702 - f1_score: 0.6227 - precision: 0.5275 - recall: 0.5782\n",
            "Epoch 102/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.8194 - accuracy: 0.7624 - f1_score: 0.6267 - precision: 0.5283 - recall: 0.5794\n",
            "Epoch 103/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.8466 - accuracy: 0.7217 - f1_score: 0.6681 - precision: 0.5286 - recall: 0.5802\n",
            "Epoch 104/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.6953 - accuracy: 0.7063 - f1_score: 0.5407 - precision: 0.5286 - recall: 0.5807\n",
            "Epoch 105/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.7027 - accuracy: 0.7519 - f1_score: 0.6690 - precision: 0.5293 - recall: 0.5825\n",
            "Epoch 106/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.8207 - accuracy: 0.6376 - f1_score: 0.5640 - precision: 0.5290 - recall: 0.5831\n",
            "Epoch 107/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.7968 - accuracy: 0.7057 - f1_score: 0.5965 - precision: 0.5293 - recall: 0.5842\n",
            "Epoch 108/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.6556 - accuracy: 0.6870 - f1_score: 0.5879 - precision: 0.5297 - recall: 0.5849\n",
            "Epoch 109/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.7665 - accuracy: 0.7040 - f1_score: 0.6200 - precision: 0.5303 - recall: 0.5855\n",
            "Epoch 110/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.8185 - accuracy: 0.7582 - f1_score: 0.6196 - precision: 0.5304 - recall: 0.5867\n",
            "Epoch 111/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.0042 - accuracy: 0.7001 - f1_score: 0.6716 - precision: 0.5309 - recall: 0.5880\n",
            "Epoch 112/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.9148 - accuracy: 0.7102 - f1_score: 0.5550 - precision: 0.5309 - recall: 0.5891\n",
            "Epoch 113/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.7471 - accuracy: 0.6935 - f1_score: 0.6039 - precision: 0.5312 - recall: 0.5900\n",
            "Epoch 114/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.7402 - accuracy: 0.7204 - f1_score: 0.5910 - precision: 0.5313 - recall: 0.5907\n",
            "Epoch 115/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6546 - accuracy: 0.7198 - f1_score: 0.6305 - precision: 0.5319 - recall: 0.5914\n",
            "Epoch 116/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.7882 - accuracy: 0.7257 - f1_score: 0.5443 - precision: 0.5323 - recall: 0.5924\n",
            "Epoch 117/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.7675 - accuracy: 0.6992 - f1_score: 0.6260 - precision: 0.5327 - recall: 0.5934\n",
            "Epoch 118/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.7397 - accuracy: 0.7383 - f1_score: 0.5599 - precision: 0.5328 - recall: 0.5937\n",
            "Epoch 119/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.6303 - accuracy: 0.7437 - f1_score: 0.6253 - precision: 0.5332 - recall: 0.5947\n",
            "Epoch 120/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.6006 - accuracy: 0.7332 - f1_score: 0.6487 - precision: 0.5337 - recall: 0.5954\n",
            "Epoch 121/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.8777 - accuracy: 0.6910 - f1_score: 0.6054 - precision: 0.5340 - recall: 0.5964\n",
            "Epoch 122/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.7645 - accuracy: 0.7608 - f1_score: 0.6052 - precision: 0.5341 - recall: 0.5973\n",
            "Epoch 123/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.6163 - accuracy: 0.7572 - f1_score: 0.6103 - precision: 0.5345 - recall: 0.5980\n",
            "Epoch 124/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.6185 - accuracy: 0.7532 - f1_score: 0.5472 - precision: 0.5348 - recall: 0.5986\n",
            "Epoch 125/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.7816 - accuracy: 0.7287 - f1_score: 0.6593 - precision: 0.5353 - recall: 0.5995\n",
            "Epoch 126/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.6531 - accuracy: 0.7089 - f1_score: 0.6054 - precision: 0.5355 - recall: 0.6001\n",
            "Epoch 127/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.6858 - accuracy: 0.7253 - f1_score: 0.5630 - precision: 0.5359 - recall: 0.6008\n",
            "Epoch 128/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.6650 - accuracy: 0.7267 - f1_score: 0.6925 - precision: 0.5362 - recall: 0.6016\n",
            "Epoch 129/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.7169 - accuracy: 0.7336 - f1_score: 0.6173 - precision: 0.5363 - recall: 0.6025\n",
            "Epoch 130/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.7164 - accuracy: 0.7039 - f1_score: 0.6156 - precision: 0.5367 - recall: 0.6036\n",
            "Epoch 131/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.6974 - accuracy: 0.7182 - f1_score: 0.6100 - precision: 0.5370 - recall: 0.6038\n",
            "Epoch 132/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5412 - accuracy: 0.7658 - f1_score: 0.6756 - precision: 0.5375 - recall: 0.6050\n",
            "Epoch 133/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.6185 - accuracy: 0.7461 - f1_score: 0.5971 - precision: 0.5378 - recall: 0.6056\n",
            "Epoch 134/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.6889 - accuracy: 0.6778 - f1_score: 0.5814 - precision: 0.5381 - recall: 0.6061\n",
            "Epoch 135/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.6870 - accuracy: 0.6953 - f1_score: 0.5151 - precision: 0.5383 - recall: 0.6065\n",
            "Epoch 136/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.6144 - accuracy: 0.7380 - f1_score: 0.6119 - precision: 0.5387 - recall: 0.6074\n",
            "Epoch 137/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.7804 - accuracy: 0.6913 - f1_score: 0.5568 - precision: 0.5388 - recall: 0.6077\n",
            "Epoch 138/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5303 - accuracy: 0.7625 - f1_score: 0.6312 - precision: 0.5391 - recall: 0.6085\n",
            "Epoch 139/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.6507 - accuracy: 0.7097 - f1_score: 0.6403 - precision: 0.5395 - recall: 0.6092\n",
            "Epoch 140/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.7226 - accuracy: 0.7179 - f1_score: 0.6378 - precision: 0.5398 - recall: 0.6097\n",
            "Epoch 141/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.6830 - accuracy: 0.7151 - f1_score: 0.5296 - precision: 0.5398 - recall: 0.6103\n",
            "Epoch 142/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.6674 - accuracy: 0.6797 - f1_score: 0.5730 - precision: 0.5398 - recall: 0.6108\n",
            "Epoch 143/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.7784 - accuracy: 0.6845 - f1_score: 0.5387 - precision: 0.5400 - recall: 0.6114\n",
            "Epoch 144/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5727 - accuracy: 0.7551 - f1_score: 0.6418 - precision: 0.5404 - recall: 0.6120\n",
            "Epoch 145/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.8977 - accuracy: 0.6944 - f1_score: 0.6482 - precision: 0.5407 - recall: 0.6128\n",
            "Epoch 146/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.8063 - accuracy: 0.6691 - f1_score: 0.5115 - precision: 0.5408 - recall: 0.6129\n",
            "Epoch 147/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5166 - accuracy: 0.7633 - f1_score: 0.6958 - precision: 0.5415 - recall: 0.6140\n",
            "Epoch 148/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6318 - accuracy: 0.7354 - f1_score: 0.6700 - precision: 0.5417 - recall: 0.6147\n",
            "Epoch 149/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5863 - accuracy: 0.7432 - f1_score: 0.6603 - precision: 0.5421 - recall: 0.6154\n",
            "Epoch 150/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5158 - accuracy: 0.7421 - f1_score: 0.6541 - precision: 0.5425 - recall: 0.6160\n",
            "Epoch 151/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.6469 - accuracy: 0.7638 - f1_score: 0.7053 - precision: 0.5428 - recall: 0.6166\n",
            "Epoch 152/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5344 - accuracy: 0.7479 - f1_score: 0.5591 - precision: 0.5430 - recall: 0.6169\n",
            "Epoch 153/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.6236 - accuracy: 0.6995 - f1_score: 0.5468 - precision: 0.5433 - recall: 0.6178\n",
            "Epoch 154/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.6406 - accuracy: 0.6980 - f1_score: 0.6343 - precision: 0.5436 - recall: 0.6182\n",
            "Epoch 155/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.7602 - accuracy: 0.6932 - f1_score: 0.5935 - precision: 0.5439 - recall: 0.6189\n",
            "Epoch 156/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.6135 - accuracy: 0.6847 - f1_score: 0.5686 - precision: 0.5437 - recall: 0.6194\n",
            "Epoch 157/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.6126 - accuracy: 0.7245 - f1_score: 0.5832 - precision: 0.5440 - recall: 0.6192\n",
            "Epoch 158/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5449 - accuracy: 0.7082 - f1_score: 0.6297 - precision: 0.5443 - recall: 0.6197\n",
            "Epoch 159/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5547 - accuracy: 0.7527 - f1_score: 0.5991 - precision: 0.5443 - recall: 0.6201\n",
            "Epoch 160/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.6585 - accuracy: 0.6795 - f1_score: 0.5905 - precision: 0.5446 - recall: 0.6206\n",
            "Epoch 161/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.6077 - accuracy: 0.7154 - f1_score: 0.6008 - precision: 0.5447 - recall: 0.6211\n",
            "Epoch 162/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.6499 - accuracy: 0.6760 - f1_score: 0.5823 - precision: 0.5450 - recall: 0.6215\n",
            "Epoch 163/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5912 - accuracy: 0.7296 - f1_score: 0.6212 - precision: 0.5453 - recall: 0.6221\n",
            "Epoch 164/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.6497 - accuracy: 0.7229 - f1_score: 0.6159 - precision: 0.5455 - recall: 0.6224\n",
            "Epoch 165/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.6249 - accuracy: 0.7649 - f1_score: 0.6318 - precision: 0.5457 - recall: 0.6230\n",
            "Epoch 166/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.7569 - accuracy: 0.6757 - f1_score: 0.6407 - precision: 0.5458 - recall: 0.6232\n",
            "Epoch 167/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.6472 - accuracy: 0.7435 - f1_score: 0.6102 - precision: 0.5460 - recall: 0.6240\n",
            "Epoch 168/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.6425 - accuracy: 0.7420 - f1_score: 0.6274 - precision: 0.5461 - recall: 0.6239\n",
            "Epoch 169/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4756 - accuracy: 0.7435 - f1_score: 0.6296 - precision: 0.5461 - recall: 0.6245\n",
            "Epoch 170/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.6226 - accuracy: 0.7291 - f1_score: 0.6512 - precision: 0.5466 - recall: 0.6250\n",
            "Epoch 171/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.6828 - accuracy: 0.7124 - f1_score: 0.6044 - precision: 0.5465 - recall: 0.6254\n",
            "Epoch 172/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5493 - accuracy: 0.7611 - f1_score: 0.6732 - precision: 0.5470 - recall: 0.6262\n",
            "Epoch 173/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.6595 - accuracy: 0.7026 - f1_score: 0.5500 - precision: 0.5469 - recall: 0.6262\n",
            "Epoch 174/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.6357 - accuracy: 0.7625 - f1_score: 0.6426 - precision: 0.5473 - recall: 0.6266\n",
            "Epoch 175/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.6248 - accuracy: 0.7019 - f1_score: 0.6292 - precision: 0.5473 - recall: 0.6272\n",
            "Epoch 176/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.6808 - accuracy: 0.7341 - f1_score: 0.5322 - precision: 0.5475 - recall: 0.6271\n",
            "Epoch 177/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5955 - accuracy: 0.7126 - f1_score: 0.6140 - precision: 0.5476 - recall: 0.6275\n",
            "Epoch 178/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5554 - accuracy: 0.7544 - f1_score: 0.6812 - precision: 0.5482 - recall: 0.6282\n",
            "Epoch 179/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5996 - accuracy: 0.7200 - f1_score: 0.6481 - precision: 0.5481 - recall: 0.6286\n",
            "Epoch 180/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.6552 - accuracy: 0.6863 - f1_score: 0.5293 - precision: 0.5482 - recall: 0.6287\n",
            "Epoch 181/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5899 - accuracy: 0.7589 - f1_score: 0.6183 - precision: 0.5484 - recall: 0.6291\n",
            "Epoch 182/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.7052 - accuracy: 0.7270 - f1_score: 0.6634 - precision: 0.5487 - recall: 0.6296\n",
            "Epoch 183/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.6833 - accuracy: 0.7486 - f1_score: 0.6049 - precision: 0.5489 - recall: 0.6299\n",
            "Epoch 184/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5493 - accuracy: 0.7647 - f1_score: 0.7027 - precision: 0.5493 - recall: 0.6306\n",
            "Epoch 185/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5849 - accuracy: 0.7428 - f1_score: 0.6401 - precision: 0.5494 - recall: 0.6307\n",
            "Epoch 186/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4692 - accuracy: 0.7587 - f1_score: 0.6755 - precision: 0.5496 - recall: 0.6314\n",
            "Epoch 187/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5066 - accuracy: 0.7373 - f1_score: 0.6101 - precision: 0.5498 - recall: 0.6315\n",
            "Epoch 188/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5837 - accuracy: 0.7587 - f1_score: 0.6497 - precision: 0.5500 - recall: 0.6321\n",
            "Epoch 189/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.6953 - accuracy: 0.6778 - f1_score: 0.6082 - precision: 0.5502 - recall: 0.6325\n",
            "Epoch 190/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4463 - accuracy: 0.7656 - f1_score: 0.6468 - precision: 0.5505 - recall: 0.6329\n",
            "Epoch 191/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5296 - accuracy: 0.7077 - f1_score: 0.6195 - precision: 0.5507 - recall: 0.6332\n",
            "Epoch 192/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5425 - accuracy: 0.7136 - f1_score: 0.6205 - precision: 0.5509 - recall: 0.6336\n",
            "Epoch 193/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5281 - accuracy: 0.7666 - f1_score: 0.6401 - precision: 0.5513 - recall: 0.6341\n",
            "Epoch 194/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4709 - accuracy: 0.7310 - f1_score: 0.5802 - precision: 0.5514 - recall: 0.6345\n",
            "Epoch 195/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5001 - accuracy: 0.7381 - f1_score: 0.6659 - precision: 0.5517 - recall: 0.6350\n",
            "Epoch 196/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.7535 - accuracy: 0.6802 - f1_score: 0.5527 - precision: 0.5518 - recall: 0.6351\n",
            "Epoch 197/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.6066 - accuracy: 0.7202 - f1_score: 0.6047 - precision: 0.5519 - recall: 0.6357\n",
            "Epoch 198/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.6819 - accuracy: 0.7073 - f1_score: 0.6097 - precision: 0.5520 - recall: 0.6356\n",
            "Epoch 199/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5931 - accuracy: 0.7277 - f1_score: 0.6199 - precision: 0.5523 - recall: 0.6356\n",
            "Epoch 200/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5558 - accuracy: 0.7102 - f1_score: 0.5472 - precision: 0.5522 - recall: 0.6362\n",
            "Epoch 201/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.7735 - f1_score: 0.6628 - precision: 0.5526 - recall: 0.6366\n",
            "Epoch 202/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6242 - accuracy: 0.7761 - f1_score: 0.7069 - precision: 0.5530 - recall: 0.6368\n",
            "Epoch 203/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5226 - accuracy: 0.7807 - f1_score: 0.6315 - precision: 0.5533 - recall: 0.6371\n",
            "Epoch 204/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4820 - accuracy: 0.7671 - f1_score: 0.6274 - precision: 0.5536 - recall: 0.6373\n",
            "Epoch 205/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5612 - accuracy: 0.7412 - f1_score: 0.5956 - precision: 0.5539 - recall: 0.6376\n",
            "Epoch 206/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5664 - accuracy: 0.7293 - f1_score: 0.6346 - precision: 0.5544 - recall: 0.6380\n",
            "Epoch 207/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5265 - accuracy: 0.7578 - f1_score: 0.6133 - precision: 0.5547 - recall: 0.6382\n",
            "Epoch 208/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5302 - accuracy: 0.7425 - f1_score: 0.6234 - precision: 0.5551 - recall: 0.6387\n",
            "Epoch 209/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4928 - accuracy: 0.7689 - f1_score: 0.7270 - precision: 0.5558 - recall: 0.6390\n",
            "Epoch 210/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5712 - accuracy: 0.7650 - f1_score: 0.5889 - precision: 0.5559 - recall: 0.6393\n",
            "Epoch 211/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.8169 - accuracy: 0.7124 - f1_score: 0.6493 - precision: 0.5561 - recall: 0.6393\n",
            "Epoch 212/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.6293 - accuracy: 0.7681 - f1_score: 0.6010 - precision: 0.5563 - recall: 0.6400\n",
            "Epoch 213/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5727 - accuracy: 0.8000 - f1_score: 0.7131 - precision: 0.5569 - recall: 0.6400\n",
            "Epoch 214/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5081 - accuracy: 0.7845 - f1_score: 0.7053 - precision: 0.5572 - recall: 0.6405\n",
            "Epoch 215/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4671 - accuracy: 0.7748 - f1_score: 0.6534 - precision: 0.5576 - recall: 0.6407\n",
            "Epoch 216/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5301 - accuracy: 0.7752 - f1_score: 0.6409 - precision: 0.5579 - recall: 0.6410\n",
            "Epoch 217/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5072 - accuracy: 0.7656 - f1_score: 0.5804 - precision: 0.5583 - recall: 0.6411\n",
            "Epoch 218/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4813 - accuracy: 0.7992 - f1_score: 0.7102 - precision: 0.5589 - recall: 0.6415\n",
            "Epoch 219/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4881 - accuracy: 0.8134 - f1_score: 0.7097 - precision: 0.5593 - recall: 0.6419\n",
            "Epoch 220/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4744 - accuracy: 0.8045 - f1_score: 0.6440 - precision: 0.5596 - recall: 0.6419\n",
            "Epoch 221/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5938 - accuracy: 0.7587 - f1_score: 0.6400 - precision: 0.5600 - recall: 0.6422\n",
            "Epoch 222/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.8398 - accuracy: 0.7520 - f1_score: 0.7126 - precision: 0.5604 - recall: 0.6424\n",
            "Epoch 223/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.6718 - accuracy: 0.7449 - f1_score: 0.4868 - precision: 0.5605 - recall: 0.6425\n",
            "Epoch 224/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5670 - accuracy: 0.7708 - f1_score: 0.6894 - precision: 0.5608 - recall: 0.6426\n",
            "Epoch 225/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5915 - accuracy: 0.7583 - f1_score: 0.5055 - precision: 0.5611 - recall: 0.6425\n",
            "Epoch 226/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5455 - accuracy: 0.7783 - f1_score: 0.6035 - precision: 0.5615 - recall: 0.6429\n",
            "Epoch 227/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5366 - accuracy: 0.7732 - f1_score: 0.7159 - precision: 0.5621 - recall: 0.6429\n",
            "Epoch 228/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5023 - accuracy: 0.7871 - f1_score: 0.6797 - precision: 0.5624 - recall: 0.6432\n",
            "Epoch 229/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.7937 - accuracy: 0.7410 - f1_score: 0.6430 - precision: 0.5627 - recall: 0.6437\n",
            "Epoch 230/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5824 - accuracy: 0.7594 - f1_score: 0.6555 - precision: 0.5630 - recall: 0.6435\n",
            "Epoch 231/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5296 - accuracy: 0.7693 - f1_score: 0.6532 - precision: 0.5634 - recall: 0.6438\n",
            "Epoch 232/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5780 - accuracy: 0.7742 - f1_score: 0.6587 - precision: 0.5638 - recall: 0.6442\n",
            "Epoch 233/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5831 - accuracy: 0.7588 - f1_score: 0.6851 - precision: 0.5641 - recall: 0.6445\n",
            "Epoch 234/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.7099 - accuracy: 0.7210 - f1_score: 0.5290 - precision: 0.5645 - recall: 0.6446\n",
            "Epoch 235/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.8445 - accuracy: 0.7069 - f1_score: 0.5942 - precision: 0.5646 - recall: 0.6451\n",
            "Epoch 236/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5934 - accuracy: 0.7350 - f1_score: 0.6081 - precision: 0.5650 - recall: 0.6449\n",
            "Epoch 237/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5938 - accuracy: 0.8208 - f1_score: 0.6656 - precision: 0.5653 - recall: 0.6451\n",
            "Epoch 238/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.6832 - accuracy: 0.7176 - f1_score: 0.6589 - precision: 0.5655 - recall: 0.6450\n",
            "Epoch 239/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.9189 - accuracy: 0.7600 - f1_score: 0.5917 - precision: 0.5657 - recall: 0.6453\n",
            "Epoch 240/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.7319 - accuracy: 0.7294 - f1_score: 0.6445 - precision: 0.5659 - recall: 0.6455\n",
            "Epoch 241/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5205 - accuracy: 0.7862 - f1_score: 0.6251 - precision: 0.5662 - recall: 0.6454\n",
            "Epoch 242/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5085 - accuracy: 0.7789 - f1_score: 0.6864 - precision: 0.5667 - recall: 0.6457\n",
            "Epoch 243/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.6662 - accuracy: 0.7682 - f1_score: 0.6392 - precision: 0.5671 - recall: 0.6459\n",
            "Epoch 244/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6317 - accuracy: 0.7448 - f1_score: 0.6446 - precision: 0.5673 - recall: 0.6464\n",
            "Epoch 245/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5165 - accuracy: 0.7783 - f1_score: 0.6213 - precision: 0.5676 - recall: 0.6464\n",
            "Epoch 246/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5286 - accuracy: 0.7547 - f1_score: 0.6661 - precision: 0.5682 - recall: 0.6465\n",
            "Epoch 247/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4785 - accuracy: 0.7674 - f1_score: 0.6834 - precision: 0.5685 - recall: 0.6469\n",
            "Epoch 248/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4702 - accuracy: 0.7966 - f1_score: 0.6663 - precision: 0.5689 - recall: 0.6471\n",
            "Epoch 249/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5137 - accuracy: 0.8075 - f1_score: 0.6753 - precision: 0.5694 - recall: 0.6473\n",
            "Epoch 250/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4825 - accuracy: 0.7730 - f1_score: 0.5959 - precision: 0.5696 - recall: 0.6475\n",
            "Epoch 251/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4425 - accuracy: 0.8034 - f1_score: 0.6830 - precision: 0.5702 - recall: 0.6477\n",
            "Epoch 252/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4746 - accuracy: 0.8004 - f1_score: 0.7164 - precision: 0.5705 - recall: 0.6480\n",
            "Epoch 253/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4674 - accuracy: 0.7643 - f1_score: 0.6493 - precision: 0.5708 - recall: 0.6482\n",
            "Epoch 254/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4640 - accuracy: 0.7858 - f1_score: 0.6173 - precision: 0.5712 - recall: 0.6485\n",
            "Epoch 255/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5340 - accuracy: 0.7833 - f1_score: 0.6847 - precision: 0.5717 - recall: 0.6485\n",
            "Epoch 256/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4588 - accuracy: 0.8005 - f1_score: 0.7177 - precision: 0.5720 - recall: 0.6488\n",
            "Epoch 257/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5239 - accuracy: 0.7911 - f1_score: 0.6111 - precision: 0.5723 - recall: 0.6490\n",
            "Epoch 258/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.6091 - accuracy: 0.7355 - f1_score: 0.6656 - precision: 0.5727 - recall: 0.6492\n",
            "Epoch 259/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4674 - accuracy: 0.8136 - f1_score: 0.7222 - precision: 0.5731 - recall: 0.6493\n",
            "Epoch 260/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5553 - accuracy: 0.7880 - f1_score: 0.6709 - precision: 0.5735 - recall: 0.6493\n",
            "Epoch 261/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5655 - accuracy: 0.7366 - f1_score: 0.6421 - precision: 0.5738 - recall: 0.6494\n",
            "Epoch 262/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.6096 - accuracy: 0.7870 - f1_score: 0.6820 - precision: 0.5741 - recall: 0.6498\n",
            "Epoch 263/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5511 - accuracy: 0.7643 - f1_score: 0.6244 - precision: 0.5743 - recall: 0.6499\n",
            "Epoch 264/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.6176 - accuracy: 0.7361 - f1_score: 0.6306 - precision: 0.5746 - recall: 0.6500\n",
            "Epoch 265/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.6084 - accuracy: 0.7750 - f1_score: 0.7153 - precision: 0.5749 - recall: 0.6501\n",
            "Epoch 266/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7871 - f1_score: 0.7021 - precision: 0.5752 - recall: 0.6504\n",
            "Epoch 267/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7900 - f1_score: 0.6807 - precision: 0.5756 - recall: 0.6507\n",
            "Epoch 268/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4568 - accuracy: 0.8115 - f1_score: 0.6471 - precision: 0.5759 - recall: 0.6507\n",
            "Epoch 269/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4508 - accuracy: 0.7977 - f1_score: 0.5864 - precision: 0.5763 - recall: 0.6508\n",
            "Epoch 270/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.6172 - accuracy: 0.7546 - f1_score: 0.6424 - precision: 0.5766 - recall: 0.6512\n",
            "Epoch 271/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4494 - accuracy: 0.7934 - f1_score: 0.6791 - precision: 0.5769 - recall: 0.6514\n",
            "Epoch 272/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5079 - accuracy: 0.7884 - f1_score: 0.7387 - precision: 0.5773 - recall: 0.6516\n",
            "Epoch 273/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.6308 - accuracy: 0.7632 - f1_score: 0.5793 - precision: 0.5775 - recall: 0.6517\n",
            "Epoch 274/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.7896 - f1_score: 0.6533 - precision: 0.5778 - recall: 0.6518\n",
            "Epoch 275/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5775 - accuracy: 0.7684 - f1_score: 0.6376 - precision: 0.5780 - recall: 0.6520\n",
            "Epoch 276/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.8084 - accuracy: 0.7639 - f1_score: 0.6279 - precision: 0.5784 - recall: 0.6522\n",
            "Epoch 277/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.8089 - f1_score: 0.6867 - precision: 0.5789 - recall: 0.6523\n",
            "Epoch 278/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4593 - accuracy: 0.8229 - f1_score: 0.7435 - precision: 0.5794 - recall: 0.6526\n",
            "Epoch 279/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4718 - accuracy: 0.8027 - f1_score: 0.6683 - precision: 0.5796 - recall: 0.6527\n",
            "Epoch 280/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5269 - accuracy: 0.7978 - f1_score: 0.7244 - precision: 0.5800 - recall: 0.6529\n",
            "Epoch 281/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5058 - accuracy: 0.7789 - f1_score: 0.6711 - precision: 0.5802 - recall: 0.6530\n",
            "Epoch 282/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.3724 - accuracy: 0.8421 - f1_score: 0.7289 - precision: 0.5805 - recall: 0.6532\n",
            "Epoch 283/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4580 - accuracy: 0.7750 - f1_score: 0.6926 - precision: 0.5809 - recall: 0.6533\n",
            "Epoch 284/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5805 - accuracy: 0.7609 - f1_score: 0.6544 - precision: 0.5811 - recall: 0.6533\n",
            "Epoch 285/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4989 - accuracy: 0.8233 - f1_score: 0.7200 - precision: 0.5813 - recall: 0.6536\n",
            "Epoch 286/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4631 - accuracy: 0.8299 - f1_score: 0.7284 - precision: 0.5817 - recall: 0.6538\n",
            "Epoch 287/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5786 - accuracy: 0.7656 - f1_score: 0.6309 - precision: 0.5820 - recall: 0.6538\n",
            "Epoch 288/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.6789 - accuracy: 0.7518 - f1_score: 0.6818 - precision: 0.5822 - recall: 0.6539\n",
            "Epoch 289/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4261 - accuracy: 0.8225 - f1_score: 0.7014 - precision: 0.5826 - recall: 0.6541\n",
            "Epoch 290/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.3829 - accuracy: 0.8204 - f1_score: 0.6990 - precision: 0.5830 - recall: 0.6544\n",
            "Epoch 291/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5351 - accuracy: 0.7922 - f1_score: 0.6903 - precision: 0.5833 - recall: 0.6546\n",
            "Epoch 292/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4825 - accuracy: 0.7850 - f1_score: 0.6533 - precision: 0.5837 - recall: 0.6549\n",
            "Epoch 293/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4519 - accuracy: 0.8287 - f1_score: 0.7642 - precision: 0.5841 - recall: 0.6551\n",
            "Epoch 294/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4551 - accuracy: 0.8245 - f1_score: 0.7195 - precision: 0.5845 - recall: 0.6553\n",
            "Epoch 295/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.7709 - accuracy: 0.7634 - f1_score: 0.6597 - precision: 0.5847 - recall: 0.6554\n",
            "Epoch 296/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.6258 - accuracy: 0.7929 - f1_score: 0.6989 - precision: 0.5850 - recall: 0.6556\n",
            "Epoch 297/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.6550 - accuracy: 0.7866 - f1_score: 0.6726 - precision: 0.5854 - recall: 0.6556\n",
            "Epoch 298/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5416 - accuracy: 0.7890 - f1_score: 0.6326 - precision: 0.5857 - recall: 0.6558\n",
            "Epoch 299/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4220 - accuracy: 0.8269 - f1_score: 0.7134 - precision: 0.5860 - recall: 0.6559\n",
            "Epoch 300/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5359 - accuracy: 0.8281 - f1_score: 0.7381 - precision: 0.5864 - recall: 0.6562\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4vDPad7Ena1-",
        "outputId": "48c7fb9c-150d-4c87-9c66-9ed714ff5758"
      },
      "source": [
        "Grid_result.best_params_"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'batch_size': 20, 'epochs': 300, 'optimizer': 'Adam'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BBwvdPN9nhkf",
        "outputId": "eb4038d7-d464-4ae7-e778-cd5371525516"
      },
      "source": [
        "print (f'Train Accuracy - : {Grid_result.score(xtrain,ytrain):.3f}')\n",
        "print (f'Test Accuracy - : {Grid_result.score(xtest,ytest):.3f}')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12/12 [==============================] - 1s 1ms/step - loss: 0.4681 - accuracy: 0.8033 - f1_score: 0.6673 - precision: 0.5868 - recall: 0.6561\n",
            "Train Accuracy - : 0.803\n",
            "3/3 [==============================] - 1s 4ms/step - loss: 0.3636 - accuracy: 0.8500 - f1_score: 0.7000 - precision: 0.5870 - recall: 0.6560\n",
            "Test Accuracy - : 0.850\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wrr7W7ag3J4Q"
      },
      "source": [
        "from sklearn import metrics"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yi4alsw16Te3",
        "outputId": "b3f37bfa-f6c5-461f-fcea-f2d681a82dfc"
      },
      "source": [
        "pred_train=Grid_result.predict(xtrain)\n",
        "pred_test=Grid_result.predict(xtest)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
            "/usr/local/lib/python3.7/dist-packages/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vkjr8MVN6cDX",
        "outputId": "978b08a4-ff13-41f9-e09d-29b62661f5cd"
      },
      "source": [
        "train_acc = metrics.accuracy_score(ytrain, pred_train)\n",
        "test_acc = metrics.accuracy_score(ytest, pred_test)\n",
        "train_f1 = metrics.f1_score(ytrain, pred_train)\n",
        "test_f1 = metrics.f1_score(ytest, pred_test)\n",
        "train_recall = metrics.recall_score(ytrain, pred_train)\n",
        "test_recall = metrics.recall_score(ytest, pred_test)\n",
        "train_precision = metrics.precision_score(ytrain, pred_train)\n",
        "test_precision = metrics.precision_score(ytest, pred_test)\n",
        "train_loss = metrics.log_loss(ytrain, pred_train)\n",
        "test_loss = metrics.log_loss(ytest, pred_test)\n",
        "\n",
        "\n",
        "print(f'\\nTrain Accuracy: {train_acc:.3f}')\n",
        "print(f'\\nTest Accuracy: {test_acc:.3f}')\n",
        "print(f'\\nTrain F1 Score: {train_f1:.3f}')\n",
        "print(f'\\nTest F1 Score: {test_f1:.3f}')\n",
        "print(f'\\nTrain recall Score: {train_recall:.3f}')\n",
        "print(f'\\nTest recall Score: {test_recall:.3f}')\n",
        "print(f'\\nTrain precision Score: {train_precision:.3f}')\n",
        "print(f'\\nTest precision Score: {test_precision:.3f}')\n",
        "print(f'\\nTrain loss Score: {train_loss:.3f}')\n",
        "print(f'\\nTest loss Score: {test_loss:.3f}')"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Train Accuracy: 0.803\n",
            "\n",
            "Test Accuracy: 0.850\n",
            "\n",
            "Train F1 Score: 0.689\n",
            "\n",
            "Test F1 Score: 0.710\n",
            "\n",
            "Train recall Score: 0.642\n",
            "\n",
            "Test recall Score: 0.733\n",
            "\n",
            "Train precision Score: 0.743\n",
            "\n",
            "Test precision Score: 0.688\n",
            "\n",
            "Train loss Score: 6.792\n",
            "\n",
            "Test loss Score: 5.181\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gL1x5FdN6hLO"
      },
      "source": [
        "import matplotlib.pyplot as plt "
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TMtsOF_Q6rDe"
      },
      "source": [
        "r_probs = [0 for _ in range(len(ytest))]\n",
        "grid_probs = Grid_result.predict_proba(xtest)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GuT2OBhB6xMP"
      },
      "source": [
        "grid_probs = grid_probs[:,1]"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0_5GCtt6y14"
      },
      "source": [
        "from sklearn.metrics import roc_curve, roc_auc_score"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jgrnLs9_603_"
      },
      "source": [
        "r_auc = roc_auc_score(ytest,r_probs)\n",
        "grid_auc = roc_auc_score(ytest,grid_probs)\n"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FhRhPlL47C6g",
        "outputId": "3a7d32de-8d92-4d62-bc66-c311c7248ca4"
      },
      "source": [
        "print('Random (chance) prediction: AUROC = %.3f' %(r_auc))\n",
        "print('Grid search test: AUROC = %.3f' %(grid_auc))\n"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Random (chance) prediction: AUROC = 0.500\n",
            "Grid search test: AUROC = 0.895\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NchQ-nqi7BT5"
      },
      "source": [
        "r_fpr , r_tpr, _ = roc_curve(ytest,r_probs)\n",
        "grid_fpr , grid_tpr, _ = roc_curve(ytest,grid_probs)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "e4Xf_Qw47UCR",
        "outputId": "718f10ae-1eb7-4d02-d9da-43caaf42eda9"
      },
      "source": [
        "plt.plot(r_fpr, r_tpr, linestyle='--', label='Random prediction AUROC = %0.3f' %r_auc)\n",
        "plt.plot(grid_fpr, grid_tpr, linestyle='--', label='Grid Search test AUROC = %0.3f' %grid_auc)\n",
        "\n",
        "\n",
        "plt.title('ROC PLOT')\n",
        "plt.xlabel('False Positive rate')\n",
        "plt.ylabel('True Positive rate')\n",
        "plt.legend()\n",
        "plt.show"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function matplotlib.pyplot.show>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}